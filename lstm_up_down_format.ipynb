{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38edcd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/XOM_2006-01-01_to_2018-01-01.csv\n",
      "3020\n",
      "(2969, 50)\n",
      "(2969, 1)\n",
      "(2969, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime(2006, 1, 1)\n",
    "end = datetime.datetime(2018, 1, 1)\n",
    "start_date_str = str(start.date())\n",
    "end_date_str = str(end.date())\n",
    "\n",
    "#how many consecutive prices are in X\n",
    "sliding_window_size = 50\n",
    "\n",
    "\"\"\"\n",
    "stocks = ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',\n",
    "          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',\n",
    "          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']\n",
    "\n",
    "\"\"\"\n",
    "stocks = ['XOM']#, 'BA', 'CAT', 'CVX', 'CSCO', 'IBM']#, 'GOOGL', 'AMZN', 'AABA']\n",
    "\n",
    "data_x = np.empty([sliding_window_size])\n",
    "data_y = np.empty([1])\n",
    "data_y_price = np.empty([1]) \n",
    "\n",
    "for stock in stocks:\n",
    "    file_name = 'data/' + stock + '_' + start_date_str + '_to_' + end_date_str + '.csv'\n",
    "    print(file_name)\n",
    "    frame = pd.read_csv(file_name)\n",
    "    \n",
    "    #get only closing stock prices\n",
    "    frame = frame['Close']\n",
    "    \n",
    "    frame =(frame.values).reshape(-1,1)\n",
    "    data = (normalize(frame, axis=0)).squeeze()\n",
    "    print(data.size)\n",
    "    \n",
    "    \n",
    "    for i in range(data.size - sliding_window_size - 1):\n",
    "        data_sample_x = data[i:i+sliding_window_size]\n",
    "\n",
    "        #EITHER EXACT PRICE OR INCREASE/DECREASE FORMAT\n",
    "        data_sample_y_price = data[i+sliding_window_size]\n",
    "        data_sample_y = 1 if data[i+sliding_window_size] > data[i+sliding_window_size - 1] else 0\n",
    "        data_x = np.vstack([data_x , data_sample_x])\n",
    "        data_y = np.vstack([data_y , data_sample_y])\n",
    "        data_y_price = np.vstack([data_y_price , data_sample_y_price])\n",
    "#remove 1st element, which was created by np.empty\n",
    "data_x = data_x[1:]\n",
    "data_y = data_y[1:]\n",
    "data_y_price = data_y_price[1:]\n",
    "\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)\n",
    "print(data_y_price.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6313af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training, validation, and test set\n",
    "\n",
    "number_of_samples = data_x.shape[0]\n",
    "\n",
    "validation_first_index = int(number_of_samples * 0.7)\n",
    "testing_first_index = int(number_of_samples * (0.7 + 0.15))\n",
    "\n",
    "data_x_train = data_x[:validation_first_index]\n",
    "data_y_train = data_y[:validation_first_index]\n",
    "\n",
    "data_x_val = data_x[validation_first_index:testing_first_index]\n",
    "data_y_val = data_y[validation_first_index:testing_first_index]\n",
    "\n",
    "data_x_test = data_x[testing_first_index:]\n",
    "data_y_test = data_y[testing_first_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "251c2e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2078, 50])\n",
      "torch.Size([2078, 1])\n",
      "torch.Size([445, 50])\n",
      "torch.Size([445, 1])\n",
      "torch.Size([446, 50])\n",
      "torch.Size([446, 1])\n"
     ]
    }
   ],
   "source": [
    "#transform to tensors\n",
    "X_train_tensors = Variable(torch.Tensor(data_x_train))\n",
    "X_val_tensors = Variable(torch.Tensor(data_x_val))\n",
    "X_test_tensors = Variable(torch.Tensor(data_x_test))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(data_y_train))\n",
    "y_val_tensors = Variable(torch.Tensor(data_y_val)) \n",
    "y_test_tensors = Variable(torch.Tensor(data_y_test)) \n",
    "\n",
    "print(X_train_tensors.shape)\n",
    "print(y_train_tensors.shape)\n",
    "print(X_val_tensors.shape)\n",
    "print(y_val_tensors.shape)\n",
    "print(X_test_tensors.shape)\n",
    "print(y_test_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "360f6441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: torch.Size([2078, 1, 50]) torch.Size([2078, 1])\n",
      "Validation Shape: torch.Size([445, 1, 50]) torch.Size([445, 1])\n",
      "Testing Shape: torch.Size([446, 1, 50]) torch.Size([446, 1])\n"
     ]
    }
   ],
   "source": [
    "#reshaping to rows, timestamps, features\n",
    "\n",
    "X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "\n",
    "X_val_tensors_final = torch.reshape(X_val_tensors,   (X_val_tensors.shape[0], 1, X_val_tensors.shape[1]))\n",
    "\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) \n",
    "\n",
    "print(\"Training Shape:\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "print(\"Validation Shape:\", X_val_tensors_final.shape, y_val_tensors.shape)\n",
    "print(\"Testing Shape:\", X_test_tensors_final.shape, y_test_tensors.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ad8eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers \n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 64) #fully connected 1\n",
    "        self.fc_2 =  nn.Linear(128, 64) #fully connected 2\n",
    "        self.fc = nn.Linear(64, num_classes) #fully connected last layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.rand(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.rand(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        #print(hn.shape)\n",
    "        #is layers > 1, get only last element\n",
    "        hn = hn[-1]\n",
    "        #print(hn.shape)\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        #print(hn.shape)\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        #out = self.fc_2(out) #2nd Dense\n",
    "        #out = self.relu(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4cd9c8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 0.50866, validation loss: 0.44950\n",
      "Epoch: 100, training loss: 0.25058, validation loss: 0.24938\n",
      "Epoch: 200, training loss: 0.25013, validation loss: 0.25220\n",
      "Epoch: 300, training loss: 0.24981, validation loss: 0.25157\n",
      "Epoch: 400, training loss: 0.24972, validation loss: 0.25085\n",
      "Epoch: 500, training loss: 0.25010, validation loss: 0.25125\n",
      "Epoch: 600, training loss: 0.24998, validation loss: 0.25097\n",
      "Epoch: 700, training loss: 0.24996, validation loss: 0.25075\n",
      "Epoch: 800, training loss: 0.24990, validation loss: 0.25052\n",
      "Epoch: 900, training loss: 0.24989, validation loss: 0.25079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.001 #0.001 lr\n",
    "\n",
    "input_size = 50 #number of features\n",
    "hidden_size = 10 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "num_classes = 1 #number of output classes \n",
    "\n",
    "lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1])\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate) \n",
    "\n",
    "lowest_loss = 999999\n",
    "for epoch in range(num_epochs):\n",
    "    output = lstm1.forward(X_train_tensors_final) #forward pass\n",
    "    optimizer.zero_grad()\n",
    " \n",
    "    loss = criterion(output, y_train_tensors)\n",
    " \n",
    "    loss.backward() #calculates the loss of the loss function\n",
    " \n",
    "    optimizer.step()\n",
    "    \n",
    "    #validation and early stopping\n",
    "    lstm1.eval()\n",
    "    output = lstm1(X_val_tensors_final)\n",
    "    val_loss = criterion(output, y_val_tensors)\n",
    "    if val_loss.item() < lowest_loss:\n",
    "        lowest_loss = val_loss.item()\n",
    "        torch.save(lstm1.state_dict(), \"checkpoint.pt\")\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, training loss: %1.5f, validation loss: %1.5f\" % (epoch, loss, val_loss))\n",
    "\n",
    "    \n",
    "\n",
    "# load the last checkpoint with the best model\n",
    "lstm1.load_state_dict(torch.load('checkpoint.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15781e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "correctness: 0.48206\n",
      "loss: 0.51794\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "with torch.no_grad():\n",
    "    output = torch.round(lstm1.forward(X_test_tensors_final))\n",
    "    acc = torch.eq(output, y_test_tensors)\n",
    "    print(len([0 for x in output if x == 1]))\n",
    "    print(\"correctness: %1.5f\" % ((sum(acc)/ y_test_tensors.shape[0]).item()))\n",
    "    print(\"loss: %1.5f\" % (criterion(output, y_test_tensors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a58acaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.plot(output, label='prediction')\n",
    "#plt.plot(y_test_tensors, label='real')\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ab48055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_new = X_test_tensors_final[0:1]\\ny_test_tensors\\nprint(X_new.shape, X_test_tensors_final.shape, y_test_tensors.shape)\\noutput = []\\nwith torch.no_grad():\\n    for i in range(100):\\n        \\n        out = lstm1.forward(X_new)\\n        output.append(out)\\n        \\n        X_new = X_new[:, :, 1:50]\\n\\n        X_new = torch.cat((X_new, out.unsqueeze(1)), dim=2)\\n\\n    \\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generative mode\n",
    "\"\"\"\n",
    "X_new = X_test_tensors_final[0:1]\n",
    "y_test_tensors\n",
    "print(X_new.shape, X_test_tensors_final.shape, y_test_tensors.shape)\n",
    "output = []\n",
    "with torch.no_grad():\n",
    "    for i in range(100):\n",
    "        \n",
    "        out = lstm1.forward(X_new)\n",
    "        output.append(out)\n",
    "        \n",
    "        X_new = X_new[:, :, 1:50]\n",
    "\n",
    "        X_new = torch.cat((X_new, out.unsqueeze(1)), dim=2)\n",
    "\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f52f8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD measurment of profit, like if price n > price n-1 and model predicts that then good\n",
    "\n",
    "#OR EVEN BETTER   calculate % change and if its + or -      FOR BOTH BUY AND SHORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "943efbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngood = 0\\nbad = 0\\nlast_pred = 0\\nlast_true = 0\\nfor pred_y, real_y in zip(output, y_test_tensors):\\n    if pred_y > last_pred and real_y > last_true:\\n        good+=1\\n    elif pred_y > last_pred and real_y < last_true:\\n        bad+=1\\n    elif pred_y < last_pred and real_y < last_true:\\n        good+=1\\n    elif pred_y < last_pred and real_y > last_true:\\n        bad+=1\\n    last_pred = pred_y\\n    last_true = real_y\\nprint(good, bad, output.shape, y_test_tensors)\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "good = 0\n",
    "bad = 0\n",
    "last_pred = 0\n",
    "last_true = 0\n",
    "for pred_y, real_y in zip(output, y_test_tensors):\n",
    "    if pred_y > last_pred and real_y > last_true:\n",
    "        good+=1\n",
    "    elif pred_y > last_pred and real_y < last_true:\n",
    "        bad+=1\n",
    "    elif pred_y < last_pred and real_y < last_true:\n",
    "        good+=1\n",
    "    elif pred_y < last_pred and real_y > last_true:\n",
    "        bad+=1\n",
    "    last_pred = pred_y\n",
    "    last_true = real_y\n",
    "print(good, bad, output.shape, y_test_tensors)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "69d8b07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Money after investing: 1008.16\n"
     ]
    }
   ],
   "source": [
    "#EXPERIMENT let's invest using our model and see if me make a profit\n",
    "money = 1000\n",
    "\n",
    "#get prices matching the test dataset\n",
    "data_y_price_test = data_y_price[testing_first_index:]\n",
    "with torch.no_grad():\n",
    "    output = torch.round(lstm1.forward(X_test_tensors_final))\n",
    "\n",
    "for i in range(1, data_y_price_test.shape[0]):\n",
    " \n",
    "    #if the model predicts that the price will rise then hold it\n",
    "    if output[i].item()==1:\n",
    "        money = money * data_y_price_test[i].item() / data_y_price_test[i-1].item()\n",
    "    #if the model predicts that the price will decrease then sell it and buy it the next day\n",
    "    else:\n",
    "        money = money * data_y_price_test[i-1].item() / data_y_price_test[i].item()\n",
    "\n",
    "print(\"Money after investing: %1.2f\" % money)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ce06751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 392\n"
     ]
    }
   ],
   "source": [
    "print(len([i for i in output if i ==1]), len([i for i in output if i ==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9503f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80847255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f9669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
