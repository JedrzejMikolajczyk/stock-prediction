{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa5db51",
   "metadata": {},
   "source": [
    "# Predicting if stock's value will go UP or DOWN with Long Short-Term Memory Network\n",
    "The data is arranged in the following way:\n",
    "\n",
    "X: stock's value for 50 consecutive days\n",
    "\n",
    "y: 1 if stock's value on 51st day is higher than on 50th day, or 0 if it is not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2de20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/AAPL_2006-01-01_to_2018-01-01.csv\n",
      "3019\n",
      "(2968, 50)\n",
      "(2968, 1)\n",
      "(2968, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime(2006, 1, 1)\n",
    "end = datetime.datetime(2018, 1, 1)\n",
    "start_date_str = str(start.date())\n",
    "end_date_str = str(end.date())\n",
    "\n",
    "#how many consecutive prices are in X\n",
    "sliding_window_size = 50\n",
    "\n",
    "\"\"\"\n",
    "stocks = ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',\n",
    "          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',\n",
    "          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']\n",
    "\n",
    "\"\"\"\n",
    "stocks = ['AAPL']#, 'BA', 'CAT', 'CVX', 'CSCO', 'IBM']#, 'GOOGL', 'AMZN', 'AABA']\n",
    "\n",
    "data_x = np.empty([sliding_window_size])\n",
    "data_y = np.empty([1])\n",
    "data_y_price = np.empty([1]) \n",
    "\n",
    "for stock in stocks:\n",
    "    file_name = 'data/' + stock + '_' + start_date_str + '_to_' + end_date_str + '.csv'\n",
    "    print(file_name)\n",
    "    frame = pd.read_csv(file_name)\n",
    "    \n",
    "    #get only closing stock prices\n",
    "    frame = frame['Close']\n",
    "    \n",
    "    frame =(frame.values).reshape(-1,1)\n",
    "    data = (normalize(frame, axis=0)).squeeze()\n",
    "    print(\"Days: \", data.size)\n",
    "    \n",
    "    \n",
    "    for i in range(data.size - sliding_window_size - 1):\n",
    "        data_sample_x = data[i:i+sliding_window_size]\n",
    "\n",
    "        #EITHER EXACT PRICE OR INCREASE/DECREASE FORMAT\n",
    "        data_sample_y_price = data[i+sliding_window_size]\n",
    "        data_sample_y = 1 if data[i+sliding_window_size] > data[i+sliding_window_size - 1] else 0\n",
    "        data_x = np.vstack([data_x , data_sample_x])\n",
    "        data_y = np.vstack([data_y , data_sample_y])\n",
    "        data_y_price = np.vstack([data_y_price , data_sample_y_price])\n",
    "#remove 1st element, which was created by np.empty\n",
    "data_x = data_x[1:]\n",
    "data_y = data_y[1:]\n",
    "data_y_price = data_y_price[1:]\n",
    "\n",
    "print(\"X: \", data_x.shape)\n",
    "print(\"y: \", data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb952b",
   "metadata": {},
   "source": [
    "### Split data into training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68cd014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_samples = data_x.shape[0]\n",
    "\n",
    "validation_first_index = int(number_of_samples * 0.7)\n",
    "testing_first_index = int(number_of_samples * (0.7 + 0.15))\n",
    "\n",
    "data_x_train = data_x[:validation_first_index]\n",
    "data_y_train = data_y[:validation_first_index]\n",
    "\n",
    "data_x_val = data_x[validation_first_index:testing_first_index]\n",
    "data_y_val = data_y[validation_first_index:testing_first_index]\n",
    "\n",
    "data_x_test = data_x[testing_first_index:]\n",
    "data_y_test = data_y[testing_first_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577584a6",
   "metadata": {},
   "source": [
    "### Transform data to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab94e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2077, 50])\n",
      "torch.Size([2077, 1])\n",
      "torch.Size([445, 50])\n",
      "torch.Size([445, 1])\n",
      "torch.Size([446, 50])\n",
      "torch.Size([446, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_tensors = Variable(torch.Tensor(data_x_train))\n",
    "X_val_tensors = Variable(torch.Tensor(data_x_val))\n",
    "X_test_tensors = Variable(torch.Tensor(data_x_test))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(data_y_train))\n",
    "y_val_tensors = Variable(torch.Tensor(data_y_val)) \n",
    "y_test_tensors = Variable(torch.Tensor(data_y_test)) \n",
    "\n",
    "print(\"Training X: \", X_train_tensors.shape)\n",
    "print(\"Training y: \", y_train_tensors.shape)\n",
    "print(\"Validation X: \", X_val_tensors.shape)\n",
    "print(\"Validation y: \", y_val_tensors.shape)\n",
    "print(\"Testing X: \", X_test_tensors.shape)\n",
    "print(\"Testing y: \", y_test_tensors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32928b55",
   "metadata": {},
   "source": [
    "### Change dimensions to (rows, timestamps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22dcebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: torch.Size([2077, 1, 50]) torch.Size([2077, 1])\n",
      "Validation Shape: torch.Size([445, 1, 50]) torch.Size([445, 1])\n",
      "Testing Shape: torch.Size([446, 1, 50]) torch.Size([446, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "\n",
    "X_val_tensors_final = torch.reshape(X_val_tensors,   (X_val_tensors.shape[0], 1, X_val_tensors.shape[1]))\n",
    "\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) \n",
    "\n",
    "print(\"Training Shape:\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "print(\"Validation Shape:\", X_val_tensors_final.shape, y_val_tensors.shape)\n",
    "print(\"Testing Shape:\", X_test_tensors_final.shape, y_test_tensors.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97a524",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory Network with 2 Linear Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b182f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers \n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 64) #fully connected 1\n",
    "        self.fc_2 =  nn.Linear(128, 64) #fully connected 2\n",
    "        self.fc = nn.Linear(64, num_classes) #fully connected last layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.rand(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.rand(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        #print(hn.shape)\n",
    "        #is layers > 1, get only last element\n",
    "        hn = hn[-1]\n",
    "        #print(hn.shape)\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        #print(hn.shape)\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        #out = self.fc_2(out) #2nd Dense\n",
    "        #out = self.relu(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e045a6",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0601a261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 0.49568, validation loss: 0.47242\n",
      "Epoch: 100, training loss: 0.24987, validation loss: 0.25199\n",
      "Epoch: 200, training loss: 0.24991, validation loss: 0.25127\n",
      "Epoch: 300, training loss: 0.24985, validation loss: 0.25023\n",
      "Epoch: 400, training loss: 0.24970, validation loss: 0.25035\n",
      "Epoch: 500, training loss: 0.24975, validation loss: 0.25006\n",
      "Epoch: 600, training loss: 0.24938, validation loss: 0.25075\n",
      "Epoch: 700, training loss: 0.24978, validation loss: 0.24996\n",
      "Epoch: 800, training loss: 0.24981, validation loss: 0.25027\n",
      "Epoch: 900, training loss: 0.24965, validation loss: 0.25008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.001 #0.001 lr\n",
    "\n",
    "input_size = 50 #number of features\n",
    "hidden_size = 10 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "num_classes = 1 #number of output classes \n",
    "\n",
    "lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1])\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate) \n",
    "\n",
    "lowest_loss = 999999\n",
    "for epoch in range(num_epochs):\n",
    "    output = lstm1.forward(X_train_tensors_final) #forward pass\n",
    "    optimizer.zero_grad()\n",
    " \n",
    "    loss = criterion(output, y_train_tensors)\n",
    " \n",
    "    loss.backward() #calculates the loss of the loss function\n",
    " \n",
    "    optimizer.step()\n",
    "    \n",
    "    #validation and early stopping\n",
    "    lstm1.eval()\n",
    "    output = lstm1(X_val_tensors_final)\n",
    "    val_loss = criterion(output, y_val_tensors)\n",
    "    if val_loss.item() < lowest_loss:\n",
    "        lowest_loss = val_loss.item()\n",
    "        torch.save(lstm1.state_dict(), \"checkpoint.pt\")\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, training loss: %1.5f, validation loss: %1.5f\" % (epoch, loss, val_loss))\n",
    "\n",
    "    \n",
    "\n",
    "# load the last checkpoint with the best model\n",
    "lstm1.load_state_dict(torch.load('checkpoint.pt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d037a",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09085493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correctness: 0.55830\n",
      "loss: 0.44170\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = torch.round(lstm1.forward(X_test_tensors_final))\n",
    "    acc = torch.eq(output, y_test_tensors)\n",
    "    print(\"correctness: %1.5f\" % ((sum(acc)/ y_test_tensors.shape[0]).item()))\n",
    "    print(\"loss: %1.5f\" % (criterion(output, y_test_tensors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b6154a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.plot(output, label='prediction')\n",
    "#plt.plot(y_test_tensors, label='real')\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b96b9239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_new = X_test_tensors_final[0:1]\\ny_test_tensors\\nprint(X_new.shape, X_test_tensors_final.shape, y_test_tensors.shape)\\noutput = []\\nwith torch.no_grad():\\n    for i in range(100):\\n        \\n        out = lstm1.forward(X_new)\\n        output.append(out)\\n        \\n        X_new = X_new[:, :, 1:50]\\n\\n        X_new = torch.cat((X_new, out.unsqueeze(1)), dim=2)\\n\\n\\ngood = 0\\nbad = 0\\nlast_pred = 0\\nlast_true = 0\\nfor pred_y, real_y in zip(output, y_test_tensors):\\n    if pred_y > last_pred and real_y > last_true:\\n        good+=1\\n    elif pred_y > last_pred and real_y < last_true:\\n        bad+=1\\n    elif pred_y < last_pred and real_y < last_true:\\n        good+=1\\n    elif pred_y < last_pred and real_y > last_true:\\n        bad+=1\\n    last_pred = pred_y\\n    last_true = real_y\\nprint(good, bad, output.shape, y_test_tensors)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generative mode\n",
    "\"\"\"\n",
    "X_new = X_test_tensors_final[0:1]\n",
    "y_test_tensors\n",
    "print(X_new.shape, X_test_tensors_final.shape, y_test_tensors.shape)\n",
    "output = []\n",
    "with torch.no_grad():\n",
    "    for i in range(100):\n",
    "        \n",
    "        out = lstm1.forward(X_new)\n",
    "        output.append(out)\n",
    "        \n",
    "        X_new = X_new[:, :, 1:50]\n",
    "\n",
    "        X_new = torch.cat((X_new, out.unsqueeze(1)), dim=2)\n",
    "\n",
    "\n",
    "good = 0\n",
    "bad = 0\n",
    "last_pred = 0\n",
    "last_true = 0\n",
    "for pred_y, real_y in zip(output, y_test_tensors):\n",
    "    if pred_y > last_pred and real_y > last_true:\n",
    "        good+=1\n",
    "    elif pred_y > last_pred and real_y < last_true:\n",
    "        bad+=1\n",
    "    elif pred_y < last_pred and real_y < last_true:\n",
    "        good+=1\n",
    "    elif pred_y < last_pred and real_y > last_true:\n",
    "        bad+=1\n",
    "    last_pred = pred_y\n",
    "    last_true = real_y\n",
    "print(good, bad, output.shape, y_test_tensors)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa2c098",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "Let's invest using our model and see if me make a profit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a54dc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Money after investing: 1499.10\n"
     ]
    }
   ],
   "source": [
    "money = 1000\n",
    "\n",
    "#get prices matching the test dataset\n",
    "data_y_price_test = data_y_price[testing_first_index:]\n",
    "with torch.no_grad():\n",
    "    output = torch.round(lstm1.forward(X_test_tensors_final))\n",
    "\n",
    "for i in range(1, data_y_price_test.shape[0]):\n",
    " \n",
    "    #if the model predicts that the price will rise then hold it\n",
    "    if output[i].item()==1:\n",
    "        money = money * data_y_price_test[i].item() / data_y_price_test[i-1].item()\n",
    "    #if the model predicts that the price will decrease then sell it and buy it the next day\n",
    "    else:\n",
    "        money = money * data_y_price_test[i-1].item() / data_y_price_test[i].item()\n",
    "\n",
    "print(\"Money after investing: %1.2f\" % money)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55600972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len([i for i in output if i ==1]), len([i for i in output if i ==0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
